{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10445969,"sourceType":"datasetVersion","datasetId":4327413},{"sourceId":6105,"sourceType":"modelInstanceVersion","modelInstanceId":4648,"modelId":2804}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing dependencies\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm.notebook import tqdm\n\nimport tensorflow as tf\nfrom tensorflow.keras import *\nfrom tensorflow.keras.optimizers import AdamW\nfrom tensorflow.keras.callbacks import Callback\nimport keras_cv\n\n\nBATCH_SIZE = 4\nGLOBAL_CLIPNORM = 10.0\n\nAUTO = tf.data.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2025-01-12T17:12:30.606653Z","iopub.execute_input":"2025-01-12T17:12:30.606993Z","iopub.status.idle":"2025-01-12T17:12:46.360291Z","shell.execute_reply.started":"2025-01-12T17:12:30.606968Z","shell.execute_reply":"2025-01-12T17:12:46.359587Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <span style=\"color:#e74c3c;\"> </span> Preprocessing","metadata":{}},{"cell_type":"code","source":"# a function for converting txt file to list\ndef parse_txt_annot(img_path, txt_path):\n    img = cv2.imread(img_path)\n    w = int(img.shape[0])\n    h = int(img.shape[1])\n\n    file_label = open(txt_path, \"r\")\n    lines = file_label.read().split('\\n')\n    \n    boxes = []\n    classes = []\n    \n    if lines[0] == '':\n        return img_path, classes, boxes\n    else:\n        for i in range(0, int(len(lines))):\n            objbud=lines[i].split(' ')\n            class_ = int(objbud[0])\n        \n            x1 = float(objbud[1])\n            y1 = float(objbud[2])\n            w1 = float(objbud[3])\n            h1 = float(objbud[4])\n        \n            xmin = int((x1*w) - (w1*w)/2.0)\n            ymin = int((y1*h) - (h1*h)/2.0)\n            xmax = int((x1*w) + (w1*w)/2.0)\n            ymax = int((y1*h) + (h1*h)/2.0)\n    \n            boxes.append([xmin ,ymin ,xmax ,ymax])\n            classes.append(class_)\n    \n    return img_path, classes, boxes\n\n\n# a function for creating file paths list \ndef create_paths_list(path):\n    full_path = []\n    images = sorted(os.listdir(path))\n    \n    for i in images:\n        full_path.append(os.path.join(path, i))\n        \n    return full_path\n\n\nclass_ids = ['label0', 'label1', 'label2']\nclass_mapping = dict(zip(range(len(class_ids)), class_ids))\n\nclass_mapping","metadata":{"execution":{"iopub.status.busy":"2025-01-12T17:12:46.361713Z","iopub.execute_input":"2025-01-12T17:12:46.362172Z","iopub.status.idle":"2025-01-12T17:12:46.373963Z","shell.execute_reply.started":"2025-01-12T17:12:46.362149Z","shell.execute_reply":"2025-01-12T17:12:46.373039Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# a function for creating a dict format of files\ndef creating_files(img_files_paths, annot_files_paths):\n    \n    img_files = create_paths_list(img_files_paths)\n    annot_files = create_paths_list(annot_files_paths)\n    \n    image_paths = []\n    bbox = []\n    classes = []\n    \n    for i in range(0,len(img_files)):\n        image_path_, classes_, bbox_ = parse_txt_annot(img_files[i], annot_files[i])\n        image_paths.append(image_path_)\n        bbox.append(bbox_)\n        classes.append(classes_)\n        \n    image_paths = tf.ragged.constant(image_paths)\n    bbox = tf.ragged.constant(bbox)\n    classes = tf.ragged.constant(classes)\n    \n    return image_paths, classes, bbox","metadata":{"execution":{"iopub.status.busy":"2025-01-12T17:12:46.375140Z","iopub.execute_input":"2025-01-12T17:12:46.375373Z","iopub.status.idle":"2025-01-12T17:12:46.391921Z","shell.execute_reply.started":"2025-01-12T17:12:46.375352Z","shell.execute_reply":"2025-01-12T17:12:46.391126Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# applying functions\ntrain_img_paths, train_classes, train_bboxes = creating_files('/kaggle/input/medical-image-dataset-brain-tumor-detection/BrainTumorYolov8/train/images', \n                                                              '/kaggle/input/medical-image-dataset-brain-tumor-detection/BrainTumorYolov8/train/labels')\n\nvalid_img_paths, valid_classes, valid_bboxes = creating_files('/kaggle/input/medical-image-dataset-brain-tumor-detection/BrainTumorYolov8/valid/images', \n                                                              '/kaggle/input/medical-image-dataset-brain-tumor-detection/BrainTumorYolov8/valid/labels')\n\ntest_img_paths, test_classes, test_bboxes = creating_files('/kaggle/input/medical-image-dataset-brain-tumor-detection/BrainTumorYolov8/test/images', \n                                                            '/kaggle/input/medical-image-dataset-brain-tumor-detection/BrainTumorYolov8/test/labels')","metadata":{"execution":{"iopub.status.busy":"2025-01-12T17:12:46.394127Z","iopub.execute_input":"2025-01-12T17:12:46.394433Z","iopub.status.idle":"2025-01-12T17:13:23.887723Z","shell.execute_reply.started":"2025-01-12T17:12:46.394405Z","shell.execute_reply":"2025-01-12T17:13:23.886930Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <span style=\"color:#e74c3c;\"> Creating </span> Datasets","metadata":{}},{"cell_type":"code","source":"# reading and resizing images\ndef img_preprocessing(img_path):\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img, channels = 3)\n    img = tf.cast(img, tf.float32) \n    \n    return img\n\n\nresizing = keras_cv.layers.JitteredResize(\n    target_size=(640, 640),\n    scale_factor=(0.8, 1.25),\n    bounding_box_format=\"xyxy\")\n\n# loading dataset\ndef load_ds(img_paths, classes, bbox):\n    img = img_preprocessing(img_paths)\n\n    bounding_boxes = {\n        \"classes\": tf.cast(classes, dtype=tf.float32),\n        \"boxes\": bbox }\n    \n    return {\"images\": img, \"bounding_boxes\": bounding_boxes}\n\ndef dict_to_tuple(inputs):\n    return inputs[\"images\"], inputs[\"bounding_boxes\"]","metadata":{"execution":{"iopub.status.busy":"2025-01-12T17:13:23.888774Z","iopub.execute_input":"2025-01-12T17:13:23.889056Z","iopub.status.idle":"2025-01-12T17:13:23.921260Z","shell.execute_reply.started":"2025-01-12T17:13:23.889032Z","shell.execute_reply":"2025-01-12T17:13:23.920594Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating dataset loaders and tf.datasets\ntrain_loader = tf.data.Dataset.from_tensor_slices((train_img_paths, train_classes, train_bboxes))\ntrain_dataset = (train_loader\n                 .map(load_ds, num_parallel_calls = AUTO)\n                 .shuffle(BATCH_SIZE*10)\n                 .ragged_batch(BATCH_SIZE, drop_remainder = True)\n                 .map(resizing, num_parallel_calls = AUTO)\n                 .map(dict_to_tuple, num_parallel_calls = AUTO)\n                 .prefetch(AUTO))\n\n\nvalid_loader = tf.data.Dataset.from_tensor_slices((valid_img_paths, valid_classes, valid_bboxes))\nvalid_dataset = (valid_loader\n                 .map(load_ds, num_parallel_calls = AUTO)\n                 .ragged_batch(BATCH_SIZE, drop_remainder = True)\n                 .map(resizing, num_parallel_calls = AUTO)\n                 .map(dict_to_tuple, num_parallel_calls = AUTO)\n                 .prefetch(AUTO))\n\n\ntest_loader = tf.data.Dataset.from_tensor_slices((test_img_paths, test_classes, test_bboxes))\ntest_dataset = (test_loader\n                .map(load_ds, num_parallel_calls = AUTO)\n                .ragged_batch(BATCH_SIZE, drop_remainder = True)\n                .map(resizing, num_parallel_calls = AUTO)\n                .map(dict_to_tuple, num_parallel_calls = AUTO)\n                .prefetch(AUTO))","metadata":{"execution":{"iopub.status.busy":"2025-01-12T17:13:23.922227Z","iopub.execute_input":"2025-01-12T17:13:23.922480Z","iopub.status.idle":"2025-01-12T17:13:30.229024Z","shell.execute_reply.started":"2025-01-12T17:13:23.922452Z","shell.execute_reply":"2025-01-12T17:13:30.228324Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# a function to visualize samples from a dataset\n\ndef visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n    inputs = next(iter(inputs.take(1)))\n    images, bounding_boxes = inputs[0], inputs[1]\n    \n    keras_cv.visualization.plot_bounding_box_gallery(\n        images,\n        value_range=value_range,\n        rows=rows,\n        cols=cols,\n        y_true=bounding_boxes,\n        scale = 8,\n        font_scale = 0.8,\n        line_thickness=2,\n        dpi = 100,\n        bounding_box_format=bounding_box_format,\n        class_mapping=class_mapping,\n        true_color = (192, 57, 43))","metadata":{"execution":{"iopub.status.busy":"2025-01-12T17:13:30.230120Z","iopub.execute_input":"2025-01-12T17:13:30.230428Z","iopub.status.idle":"2025-01-12T17:13:30.236062Z","shell.execute_reply.started":"2025-01-12T17:13:30.230399Z","shell.execute_reply":"2025-01-12T17:13:30.235237Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# examples images and annotations from training daatset\nvisualize_dataset(train_dataset, bounding_box_format=\"xyxy\", value_range=(0, 255), rows=2, cols=2)","metadata":{"execution":{"iopub.status.busy":"2025-01-12T17:13:30.237103Z","iopub.execute_input":"2025-01-12T17:13:30.237356Z","iopub.status.idle":"2025-01-12T17:13:32.947607Z","shell.execute_reply.started":"2025-01-12T17:13:30.237336Z","shell.execute_reply":"2025-01-12T17:13:32.946496Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <span style=\"color:#e74c3c;\"> YOLO V8</span> Model","metadata":{}},{"cell_type":"code","source":"# creating mirrored strategy\n\nstg = tf.distribute.MirroredStrategy()","metadata":{"execution":{"iopub.status.busy":"2025-01-12T17:13:32.948642Z","iopub.execute_input":"2025-01-12T17:13:32.948882Z","iopub.status.idle":"2025-01-12T17:13:32.956165Z","shell.execute_reply.started":"2025-01-12T17:13:32.948862Z","shell.execute_reply":"2025-01-12T17:13:32.955400Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# creating pre-trained model backbone with coco weights\n\nwith stg.scope():\n    backbone = keras_cv.models.YOLOV8Backbone.from_preset(\"yolo_v8_xs_backbone_coco\")\n    \n    YOLOV8_model = keras_cv.models.YOLOV8Detector(num_classes=len(class_mapping),\n                                              bounding_box_format=\"xyxy\",\n                                              backbone=backbone, fpn_depth=1 )\n\n    optimizer = AdamW(learning_rate=0.0001, weight_decay=0.004, global_clipnorm = GLOBAL_CLIPNORM)\n\n    YOLOV8_model.compile(optimizer = optimizer, classification_loss = 'binary_crossentropy', box_loss = 'ciou')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-01-12T17:13:32.958310Z","iopub.execute_input":"2025-01-12T17:13:32.958594Z","iopub.status.idle":"2025-01-12T17:13:38.192756Z","shell.execute_reply.started":"2025-01-12T17:13:32.958560Z","shell.execute_reply":"2025-01-12T17:13:38.191902Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <span style=\"color:#e74c3c;\"> Training </span> ","metadata":{}},{"cell_type":"code","source":"hist = YOLOV8_model.fit(train_dataset, validation_data = valid_dataset,  epochs = 120)","metadata":{"execution":{"iopub.status.busy":"2025-01-12T17:13:38.193665Z","iopub.execute_input":"2025-01-12T17:13:38.193888Z","iopub.status.idle":"2025-01-12T18:46:44.619244Z","shell.execute_reply.started":"2025-01-12T17:13:38.193868Z","shell.execute_reply":"2025-01-12T18:46:44.618441Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <span style=\"color:#e74c3c;\"> Training </span> Results, Evaluation","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1,3, figsize = (18,5), dpi = 130)\n\naxs[0].grid(linestyle=\"dashdot\")\naxs[0].set_title(\"Loss\")\naxs[0].plot(hist.history['loss'][1:])\naxs[0].plot(hist.history['val_loss'][1:])\naxs[0].legend([\"train\", \"validataion\"])\n\naxs[1].grid(linestyle=\"dashdot\")\naxs[1].set_title(\"Box Loss\")\naxs[1].plot(hist.history['box_loss'])\naxs[1].plot(hist.history['val_box_loss'])\naxs[1].legend([\"train\",  \"validataion\"])\n\naxs[2].grid(linestyle=\"dashdot\")\naxs[2].set_title(\"Class Loss\")\naxs[2].plot(hist.history['class_loss'][1:])\naxs[2].plot(hist.history['val_class_loss'][1:])\naxs[2].legend([\"train\",  \"validataion\"])","metadata":{"execution":{"iopub.status.busy":"2025-01-12T18:46:44.625032Z","iopub.execute_input":"2025-01-12T18:46:44.625423Z","iopub.status.idle":"2025-01-12T18:46:45.362432Z","shell.execute_reply.started":"2025-01-12T18:46:44.625399Z","shell.execute_reply":"2025-01-12T18:46:45.361548Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <span style=\"color:#e74c3c;\"> Test </span> Predictions","metadata":{}},{"cell_type":"code","source":"def visualize_predict_detections(model, dataset, bounding_box_format):\n    images, y_true = next(iter(dataset.take(1)))\n        \n    y_pred = model.predict(images)\n    y_pred = keras_cv.bounding_box.to_ragged(y_pred)\n    \n    keras_cv.visualization.plot_bounding_box_gallery(\n        images,\n        value_range=(0, 255),\n        bounding_box_format=bounding_box_format,\n        y_true=y_true,\n        y_pred=y_pred,\n        true_color = (192, 57, 43),\n        pred_color=(255, 235, 59),\n        scale = 8,\n        font_scale = 0.8,\n        line_thickness=2,\n        dpi = 100,\n        rows=2,\n        cols=2,\n        show=True,\n        class_mapping=class_mapping,\n    )","metadata":{"execution":{"iopub.status.busy":"2025-01-12T18:46:45.363519Z","iopub.execute_input":"2025-01-12T18:46:45.363802Z","iopub.status.idle":"2025-01-12T18:46:45.369372Z","shell.execute_reply.started":"2025-01-12T18:46:45.363779Z","shell.execute_reply":"2025-01-12T18:46:45.368435Z"},"trusted":true},"outputs":[],"execution_count":null}]}